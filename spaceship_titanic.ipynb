{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baffcfbf",
   "metadata": {},
   "source": [
    "# Spaceship titanic project\n",
    "\n",
    "Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n",
    "\n",
    "Help save them and change history!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105a23d",
   "metadata": {},
   "source": [
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b19e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa75af",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of dropping all NaN, we are going to replace NaN values with the mode of the column or with\n",
    "# a text Unknown for the name, which is not used in any model and hence is useless\n",
    "\n",
    "data['Name'] = data['Name'].fillna('Unknown')\n",
    "\n",
    "# Cabins: 5305 unique values; 80% of the entered values are unique\n",
    "# They are divided in P (port) and S (starboard)\n",
    "data['Cabin'] = data['Cabin'].str.split('/').str.get(-1)\n",
    "\n",
    "fill_mode_cols = ['HomePlanet','CryoSleep','Cabin','Destination','Age','VIP']\n",
    "price_mean_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "\n",
    "for col in fill_mode_cols:\n",
    "    data[col] = data[col].fillna(data[col].mode()[0])\n",
    "        \n",
    "# For the price columns, if passenger is in CryoSleep, then NaN values will become 0.\n",
    "for col in price_mean_cols:\n",
    "    data[col] = np.where((data['CryoSleep'] == True) & (data[col].isnull()), 0, data[col])\n",
    "\n",
    "for col in price_mean_cols:\n",
    "    data[col] = data[col].fillna(data[col].mean())\n",
    "    \n",
    "# Confirm that NaN values are 0\n",
    "data.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bf51b",
   "metadata": {},
   "source": [
    "**train.csv** - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "\n",
    "**PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "**HomePlanet** - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "**CryoSleep** - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "**Cabin** - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "\n",
    "**Destination** - The planet the passenger will be debarking to.\n",
    "\n",
    "**Age** - The age of the passenger.\n",
    "\n",
    "**VIP** - Whether the passenger has paid for special VIP service during the voyage.\n",
    "\n",
    "**RoomService, FoodCourt, ShoppingMall, Spa, VRDeck** - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "\n",
    "**Name** - The first and last names of the passenger.\n",
    "\n",
    "**Transported**- Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74f8d0",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf1f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Transported people is roughly 50-50\n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='Transported')\n",
    "plt.title('Distribution of transported people')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of HomePlanet\n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='HomePlanet',hue='Transported')\n",
    "plt.title('Distribution of HomePlanet')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of CryoSleep\n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='CryoSleep',hue='Transported')\n",
    "plt.title('Distribution of people in CryoSleep')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of P vs S cabin \n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='Cabin',hue='Transported')\n",
    "plt.title('Distribution of Cabin P vs S')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Destination\n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='Destination',hue='Transported')\n",
    "plt.title('Distribution of Destination')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of VIP people\n",
    "plt.figure()\n",
    "sns.countplot(data=data,x='VIP',hue='Transported')\n",
    "plt.title('Distribution of VIP people')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25687aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting the RoomService, FoodCourt, ShoppingMall, Spa, VRDeck into bins, so that it is possible to use them\n",
    "# in the models\n",
    "\n",
    "cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "binned_cols_names = ['room_service_binned','food_court_binned','shopping_binned','spa_binned','VR_binned']\n",
    "\n",
    "bins = [0, 50, 200, 500, 1500,20000]\n",
    "labels = ['0-50', '51-200', '201-500', '501-1500','1501-20000']\n",
    "for i in range(0,len(cols)):\n",
    "    data[binned_cols_names[i]] = pd.cut(data[cols[i]], bins=bins, labels=labels, right=False)\n",
    "\n",
    "    \n",
    "# Cutting the age in bins as well\n",
    "bins = [0, 20, 40, 60, 100]\n",
    "labels = ['0-20', '21-40', '41-60', '61-100']\n",
    "data['age_binned'] = pd.cut(data['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=data,x='room_service_binned',hue='Transported')\n",
    "plt.title('Distribution of Room Service spent')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data=data,x='age_binned',hue='Transported')\n",
    "plt.title('Distribution of ages')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10427454",
   "metadata": {},
   "source": [
    "There are some interesting correlations. These columns will definitely be important in the model.\n",
    "\n",
    "**Transported** Transported people are roughly 50% of the passengers.\n",
    "\n",
    "**HomePlanet** Passengers from Europa were transported more often. For Mars, distribution is 50-50, whereas passengers from Earthers were more likely not to be transported.\n",
    "\n",
    "**CryoSleep** People that were in Cryo sleep were much more likely to be transported than people who weren't.\n",
    "\n",
    "**Port vs Seabord** Passengers in the S cabin were more likely to be transported. \n",
    "\n",
    "**Destination** Passengers going to 55 Cancri E were more likely to be transported. For the other 2 destinations, distribution was 50-50. \n",
    "\n",
    "**VIP** VIP people were quite few. In the VIP category, the majority was non-transported (by little). In the non-VIP, the majority was transported. Data is too little to be significant.\n",
    "\n",
    "Money spent in **room service** or other services seem to correlate to whether or not passengers were transported. For example, people who spent between 0-200 in these services seem to be transported more often than not. Binning the dataframe will be useful because now the binned room service, SPA, etc. can be encoded and used in the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417e389",
   "metadata": {},
   "source": [
    "### Encoding variables for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16672a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HomePlanet has 3 entries, can be dummied easily\n",
    "# CryoSleep has 2 values: True or False, can be dummied easily\n",
    "\n",
    "# Destination has only 3 unique values, can be dummied easily\n",
    "# Age has a distribution from 0 to 80, centered around 20–30 --> should be scaled if included in model\n",
    "# VIP is a boolean, easy to dummy\n",
    "\n",
    "# RoomService and similar are highly shifted towards zero but show a correlation so the binned columns will \n",
    "# be encoded\n",
    "\n",
    "feature_cols = ['HomePlanet','CryoSleep','Cabin','Destination','VIP','age_binned',\n",
    "                'room_service_binned','food_court_binned','shopping_binned','spa_binned','VR_binned']\n",
    "\n",
    "features_train = data[feature_cols]\n",
    "features_train = pd.get_dummies(features_train)\n",
    "# labels are encoded so that 1 is transported and 0 is not transported\n",
    "labels_train = data['Transported']\n",
    "\n",
    "# Perform a train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train,labels_train,test_size=0.2,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db49c0",
   "metadata": {},
   "source": [
    "### Getting the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, we re-do all the same procedures that we've done for training set, but \n",
    "# for the test.csv file\n",
    "\n",
    "test_data = pd.read_csv('test.csv')\n",
    "# Cleaning\n",
    "\n",
    "test_data['Name'] = test_data['Name'].fillna('Unknown')\n",
    "test_data['Cabin'] = test_data['Cabin'].str.split('/').str.get(-1)\n",
    "\n",
    "fill_mode_cols = ['HomePlanet','CryoSleep','Cabin','Destination','Age','VIP']\n",
    "price_mean_cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "\n",
    "for col in fill_mode_cols:\n",
    "    test_data[col] = test_data[col].fillna(test_data[col].mode()[0])\n",
    "        \n",
    "# For the price columns, if passenger is in CryoSleep, then NaN values will become 0.\n",
    "for col in price_mean_cols:\n",
    "    test_data[col] = np.where((test_data['CryoSleep'] == True) & (test_data[col].isnull()), 0, test_data[col])\n",
    "\n",
    "for col in price_mean_cols:\n",
    "    test_data[col] = test_data[col].fillna(test_data[col].mean())\n",
    "\n",
    "# Cutting the RoomService, FoodCourt, ShoppingMall, Spa, VRDeck into bins, so that it is possible to use them\n",
    "# in the models\n",
    "\n",
    "cols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "binned_cols_names = ['room_service_binned','food_court_binned','shopping_binned','spa_binned','VR_binned']\n",
    "bins = [0, 50, 200, 500, 1500,20000]\n",
    "labels = ['0-50', '51-200', '201-500', '501-1500','1501-20000']\n",
    "for i in range(0,len(cols)):\n",
    "    test_data[binned_cols_names[i]] = pd.cut(test_data[cols[i]], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Cutting the age in bins as well\n",
    "bins = [0, 20, 40, 60, 100]\n",
    "labels = ['0-20', '21-40', '41-60', '61-100']\n",
    "test_data['age_binned'] = pd.cut(test_data['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "features_test = test_data[feature_cols]\n",
    "features_test = pd.get_dummies(features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ef5aa",
   "metadata": {},
   "source": [
    "## ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be28eba2",
   "metadata": {},
   "source": [
    "### KNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Optimize neighbors number in KNN model\n",
    "knn_scores_train = []\n",
    "knn_scores_test = []\n",
    "for n in range(1,10):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    knn_scores_train.append(knn.score(X_train,y_train))\n",
    "    knn_scores_test.append(knn.score(X_test,y_test))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(knn_scores_train)\n",
    "plt.plot(knn_scores_test)\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('KNN Score')\n",
    "plt.legend(['Training set','Test set'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892cf6b5",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a3f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_scores_train = []\n",
    "rfc_scores_test = []\n",
    "for n in np.linspace(1,200,10,dtype=int):\n",
    "    rfc = RandomForestClassifier(n_estimators=n).fit(X_train,y_train)\n",
    "    rfc_scores_train.append(rfc.score(X_train,y_train))\n",
    "    rfc_scores_test.append(rfc.score(X_test,y_test))\n",
    "    \n",
    "plt.figure(2)\n",
    "plt.plot(np.linspace(1,200,10,dtype=int),rfc_scores_train)\n",
    "plt.plot(np.linspace(1,200,10,dtype=int),rfc_scores_test)\n",
    "plt.xlabel('Number of estimators')\n",
    "plt.ylabel('RFC score')\n",
    "plt.legend(['Training set','Test set'])\n",
    "plt.show()\n",
    "\n",
    "# 100 estimators (default) is a good number; now optimize depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_scores_train = []\n",
    "rfc_scores_test = []\n",
    "\n",
    "for d in range(1,20):\n",
    "    rfc = RandomForestClassifier(n_estimators = 150, max_depth = d).fit(X_train,y_train)\n",
    "    rfc_scores_train.append(rfc.score(X_train,y_train))\n",
    "    rfc_scores_test.append(rfc.score(X_test,y_test))\n",
    "    \n",
    "plt.figure(3)\n",
    "plt.plot(range(1,20),rfc_scores_train)\n",
    "plt.plot(range(1,20),rfc_scores_test)\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('RFC score')\n",
    "plt.legend(['Training set','Test set'])\n",
    "plt.show()\n",
    "\n",
    "print('Max accuracy with Random Forest:')\n",
    "print(max(rfc_scores_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86898f0",
   "metadata": {},
   "source": [
    "## Predictions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 150, max_depth = 8).fit(X_train,y_train)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['PassengerId'] = test_data['PassengerId']\n",
    "test_df['Transported'] = rfc.predict(features_test)\n",
    "\n",
    "test_df.to_csv(r'submission.csv', index=False, header=[\"PassengerId\", \"Transported\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
